{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "incoming-captain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>body {\n",
       "    margin: 0;\n",
       "    font-family: lexend;\n",
       "}\n",
       "table.dataframe {\n",
       "    border-collapse: collapse;\n",
       "    border: none;\n",
       "}\n",
       "table.dataframe tr {\n",
       "    border: none;\n",
       "}\n",
       "table.dataframe td, table.dataframe th {\n",
       "    margin: 0;\n",
       "    border: 1px solid white;\n",
       "    padding-left: 0.25em;\n",
       "    padding-right: 0.25em;\n",
       "}\n",
       "table.dataframe th:not(:empty) {\n",
       "    background-color: #fec;\n",
       "    text-align: left;\n",
       "    font-weight: normal;\n",
       "}\n",
       "table.dataframe tr:nth-child(2) th:empty {\n",
       "    border-left: none;\n",
       "    border-right: 1px dashed #888;\n",
       "}\n",
       "table.dataframe td {\n",
       "    border: 2px solid #ccf;\n",
       "    background-color: #f4f4ff;\n",
       "}\n",
       "h1 {\n",
       "    color: white;\n",
       "    background: rgb(2,0,36);\n",
       "    background: linear-gradient(90deg, rgba(2,0,36,1) 0%, rgba(238,65,79,1) 42%, rgba(0,84,255,1) 81%); \n",
       "    padding: 0.25em;\n",
       "}\n",
       "\n",
       "h3 {\n",
       "    color: white;\n",
       "    background-color: black;\n",
       "    padding: 0.25em;\n",
       "}\n",
       "\n",
       "h2 {\n",
       "    color: white;\n",
       "    background-color: #fc0362;\n",
       "    padding: 0.25em;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "css = open('notebook_css/style-table.css').read() + open('notebook_css/style-notebook.css').read()\n",
    "HTML('<style>{}</style>'.format(css))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-hungarian",
   "metadata": {},
   "source": [
    "https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html\n",
    "\n",
    "Author: @imflash217 [September/07/2021]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-blackberry",
   "metadata": {},
   "source": [
    "# TENSORS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statewide-crime",
   "metadata": {},
   "source": [
    "Tensors are specialized data structures that are very similar to arrays and matrices.\n",
    "\n",
    "टेंसर (tensor) एक बहुत ही उत्कृष्ट डेटा स्ट्रक्चर (data structure) है जो ऐरे (array) एवं मेट्रिक्स (matrix) के समकक्ष है.\n",
    "\n",
    "In PyTorch, we use Tensors to encode the inputs & outputs of the model as well as the model's parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annoying-andrews",
   "metadata": {},
   "source": [
    "Tensors are similar to Numpy `ndarrays`; except that the tensors can run on GPUs or other hardware accelerators.\n",
    "\n",
    "If fact, Tensors & Numpy arrays can share the same underlying memory, eliminating the need to copy data.\n",
    "\n",
    "Tensors are also optimized for automatic differentiation (`Autograd`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "objective-embassy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revised-carry",
   "metadata": {},
   "source": [
    "## Initializing a Tensor\n",
    "\n",
    "Tensors can be initialized in various ways:\n",
    "\n",
    "1. Directly from data\n",
    "\n",
    "2. From Numpy array\n",
    "\n",
    "3. From another Tensor\n",
    "\n",
    "4. With random or constant values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-reliance",
   "metadata": {},
   "source": [
    "### Directly from Data\n",
    "\n",
    "Tensors can be created directly from data. The **datatype** is automatically inferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "allied-authority",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[1,2],\n",
    "        [3,4],\n",
    "       ]\n",
    "\n",
    "x_data = torch.tensor(data)\n",
    "\n",
    "x_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latin-liberia",
   "metadata": {},
   "source": [
    "### From a `numpy` array\n",
    "\n",
    "Tensors can be created form numpy arrays & vice-versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "wired-permit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "\n",
    "x_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-exhibit",
   "metadata": {},
   "source": [
    "### From another Tensor\n",
    "\n",
    "The new tensor retains the properties (shape, dtype) of the argument tensor, unless explictly overridden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "australian-paragraph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor \n",
      "tensor([[1, 1],\n",
      "        [1, 1]])\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data)      ## retains the properties of x_data\n",
    "print(f\"Ones Tensor \\n{x_ones}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cordless-homeless",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor:\n",
      "tensor([[0.7202, 0.2566],\n",
      "        [0.7286, 0.9776]])\n"
     ]
    }
   ],
   "source": [
    "x_rand = torch.rand_like(x_data, dtype=torch.float)        ## overrides the data-type of x_data\n",
    "print(f\"Random Tensor:\\n{x_rand}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manual-paste",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "respective-beast",
   "metadata": {},
   "source": [
    "### With `random` or `constant` values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composite-pasta",
   "metadata": {},
   "source": [
    "`shape` is a tuple of tensor dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "spectacular-mining",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tesnor:\n",
      "tensor([[0.3070, 0.7394, 0.1978],\n",
      "        [0.1237, 0.5404, 0.0584]])\n",
      "\n",
      "Ones Tensor:\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "\n",
      "Zeros Tebsor:\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shape = (2,3,)\n",
    "\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tesnor:\\n{rand_tensor}\\n\")\n",
    "print(f\"Ones Tensor:\\n{ones_tensor}\\n\")\n",
    "print(f\"Zeros Tebsor:\\n{zeros_tensor}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-comment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "occupational-double",
   "metadata": {},
   "source": [
    "## Attributes of a Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-cream",
   "metadata": {},
   "source": [
    "Tensor attributes describe their `shape`, `dtype` (datatype) & `device` (the device they are stored on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "focused-counter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Shape of the tensor: torch.Size([2, 3])\n",
      "\n",
      "        Datatype of the tensor: torch.float32\n",
      "\n",
      "        Device of the tensor: cpu\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand((2,3))\n",
    "\n",
    "print(f\"\"\"\n",
    "        Shape of the tensor: {tensor.shape}\\n\n",
    "        Datatype of the tensor: {tensor.dtype}\\n\n",
    "        Device of the tensor: {tensor.device}\\n\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-hampshire",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "direct-longer",
   "metadata": {},
   "source": [
    "## Operations on Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civil-navigation",
   "metadata": {},
   "source": [
    "By default Tensors are created on the CPU. We need to move the tensors to GPU using `.to()` method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "private-median",
   "metadata": {},
   "source": [
    "NOTE: Copying large tensors across devices can be expensive in time and memory\n",
    "\n",
    "**If you are familiar with NumPy API then the Tensor API is a breeze to use**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "skilled-relaxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We move our tensor to GPU if its available\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to(device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "pursuant-herald",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-concord",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "automotive-portuguese",
   "metadata": {},
   "source": [
    "### Standard numpy-like indexing and slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "under-taiwan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6381, 0.3969, 0.4041, 0.9981],\n",
       "        [0.5977, 0.7554, 0.5118, 0.4986],\n",
       "        [0.8223, 0.9271, 0.1076, 0.1209],\n",
       "        [0.5900, 0.4490, 0.2765, 0.2400]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.rand((4,4))\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "missing-affiliation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: tensor([0.6381, 0.3969, 0.4041, 0.9981])\n"
     ]
    }
   ],
   "source": [
    "print(f\"First row: {tensor[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "corrected-combine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Column: tensor([0.6381, 0.5977, 0.8223, 0.5900])\n"
     ]
    }
   ],
   "source": [
    "print(f\"First Column: {tensor[:, 0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "spectacular-syntax",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Column: tensor([0.9981, 0.4986, 0.1209, 0.2400])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Last Column: {tensor[..., -1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "endless-parking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6381, 0.0000, 0.4041, 0.9981],\n",
       "        [0.5977, 0.0000, 0.5118, 0.4986],\n",
       "        [0.8223, 0.0000, 0.1076, 0.1209],\n",
       "        [0.5900, 0.0000, 0.2765, 0.2400]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[..., 1] = 0\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabulous-rapid",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "considerable-waterproof",
   "metadata": {},
   "source": [
    "### Joining Tensors\n",
    "\n",
    "You can use **`torch.cat`** to concatentate a sequence of tensors along a given dimension\n",
    "\n",
    "**`torch.stack`** is similar but subtly different from **`torch.cat`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "african-great",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6381, 0.0000, 0.4041, 0.9981, 0.6381, 0.0000, 0.4041, 0.9981, 0.6381,\n",
       "         0.0000, 0.4041, 0.9981, 0.6381, 0.0000, 0.4041, 0.9981],\n",
       "        [0.5977, 0.0000, 0.5118, 0.4986, 0.5977, 0.0000, 0.5118, 0.4986, 0.5977,\n",
       "         0.0000, 0.5118, 0.4986, 0.5977, 0.0000, 0.5118, 0.4986],\n",
       "        [0.8223, 0.0000, 0.1076, 0.1209, 0.8223, 0.0000, 0.1076, 0.1209, 0.8223,\n",
       "         0.0000, 0.1076, 0.1209, 0.8223, 0.0000, 0.1076, 0.1209],\n",
       "        [0.5900, 0.0000, 0.2765, 0.2400, 0.5900, 0.0000, 0.2765, 0.2400, 0.5900,\n",
       "         0.0000, 0.2765, 0.2400, 0.5900, 0.0000, 0.2765, 0.2400]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = torch.cat([tensor, tensor, tensor, tensor], dim=-1)\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ambient-bahrain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "white-sunglasses",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "brilliant-adelaide",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6381, 0.6381, 0.6381, 0.6381],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4041, 0.4041, 0.4041, 0.4041],\n",
       "         [0.9981, 0.9981, 0.9981, 0.9981]],\n",
       "\n",
       "        [[0.5977, 0.5977, 0.5977, 0.5977],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.5118, 0.5118, 0.5118, 0.5118],\n",
       "         [0.4986, 0.4986, 0.4986, 0.4986]],\n",
       "\n",
       "        [[0.8223, 0.8223, 0.8223, 0.8223],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1076, 0.1076, 0.1076, 0.1076],\n",
       "         [0.1209, 0.1209, 0.1209, 0.1209]],\n",
       "\n",
       "        [[0.5900, 0.5900, 0.5900, 0.5900],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2765, 0.2765, 0.2765, 0.2765],\n",
       "         [0.2400, 0.2400, 0.2400, 0.2400]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = torch.stack([tensor, tensor, tensor, tensor], dim=-1)\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "discrete-findings",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 4])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-pattern",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dress-diversity",
   "metadata": {},
   "source": [
    "### Arithmetic Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "arctic-andorra",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5666, 1.0858, 0.6889, 0.7277],\n",
       "        [1.0858, 0.8678, 0.6068, 0.6138],\n",
       "        [0.6889, 0.6068, 0.7024, 0.5440],\n",
       "        [0.7277, 0.6138, 0.5440, 0.4822]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## This computes the matrix mulatiplication between two tensors\n",
    "## y1, y2 & y3 will all have the same value\n",
    "\n",
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "y3 = torch.rand_like(tensor)\n",
    "torch.matmul(tensor, tensor.T, out=y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fewer-supply",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.equal(y1, y2)\n",
    "assert torch.equal(y2, y3)\n",
    "assert torch.equal(y3, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-tower",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "transsexual-airport",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4072, 0.0000, 0.1633, 0.9961],\n",
       "        [0.3572, 0.0000, 0.2620, 0.2486],\n",
       "        [0.6762, 0.0000, 0.0116, 0.0146],\n",
       "        [0.3482, 0.0000, 0.0764, 0.0576]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## this compute the elementwise multiplication (NOT dot product)\n",
    "## z1, z2, z3 will all have the same value\n",
    "\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor, out=z3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "particular-providence",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.equal(z1, z2)\n",
    "assert torch.equal(z2, z3)\n",
    "assert torch.equal(z3, z1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conditional-serial",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "drawn-amino",
   "metadata": {},
   "source": [
    "### Single element tensor\n",
    "\n",
    "If we have a single element tensor, then we can access the value of the tensor by `.item()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "musical-trail",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agg_item = 5.805617332458496\n",
      "agg.dtype = torch.float32\n",
      "type(agg_item) = <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(f\"agg_item = {agg_item}\\nagg.dtype = {agg.dtype}\\ntype(agg_item) = {type(agg_item)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-locking",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "difficult-theorem",
   "metadata": {},
   "source": [
    "### In-place Operations\n",
    "\n",
    "Operations that store the results into the operand itself are called **inplace ops**.\n",
    "\n",
    "These methods are denoted by a **`_` suffix**. For ex: `x.copy_(y)`, `x.t_()` (These will change `x` itself)\n",
    "\n",
    "NOTE: In-place ops saves memory; but can be problematic when computing derivatives because of an immediate loss of history. Hence, their use is discouraged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "reverse-remark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8386, 0.5396, 0.0162],\n",
      "        [0.4399, 0.3398, 0.3471]])\n",
      "\n",
      "tensor([[838.6037, 539.5958,  16.1870],\n",
      "        [439.9262, 339.7519, 347.0796]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand((2,3))\n",
    "\n",
    "print(f\"{tensor}\\n\")\n",
    "tensor.mul_(1_000)\n",
    "print(f\"{tensor}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-georgia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "noticed-electronics",
   "metadata": {},
   "source": [
    "## Bridge with NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-eclipse",
   "metadata": {},
   "source": [
    "Tensors on **CPU** and NumPy arrays can share their underlying memory locations. **Changing one will change the other**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-upper",
   "metadata": {},
   "source": [
    "### Tensor to NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "scenic-drove",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones((5,))\n",
    "print(f\"t: {t}\")\n",
    "\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "blank-polls",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "## both share the same storage.\n",
    "## so changing one will change the other\n",
    "\n",
    "t.add_(1)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "atomic-andorra",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([3., 3., 3., 3., 3.])\n",
      "n: [3. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "np.add(n, 1, out=n)\n",
    "\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-favor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
