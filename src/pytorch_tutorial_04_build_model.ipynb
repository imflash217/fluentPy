{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "eligible-polyester",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>body {\n",
       "    margin: 0;\n",
       "    font-family: lexend;\n",
       "}\n",
       "table.dataframe {\n",
       "    border-collapse: collapse;\n",
       "    border: none;\n",
       "}\n",
       "table.dataframe tr {\n",
       "    border: none;\n",
       "}\n",
       "table.dataframe td, table.dataframe th {\n",
       "    margin: 0;\n",
       "    border: 1px solid white;\n",
       "    padding-left: 0.25em;\n",
       "    padding-right: 0.25em;\n",
       "}\n",
       "table.dataframe th:not(:empty) {\n",
       "    background-color: #fec;\n",
       "    text-align: left;\n",
       "    font-weight: normal;\n",
       "}\n",
       "table.dataframe tr:nth-child(2) th:empty {\n",
       "    border-left: none;\n",
       "    border-right: 1px dashed #888;\n",
       "}\n",
       "table.dataframe td {\n",
       "    border: 2px solid #ccf;\n",
       "    background-color: #f4f4ff;\n",
       "}\n",
       "h1 {\n",
       "    color: white;\n",
       "    background: rgb(2,0,36);\n",
       "    background: linear-gradient(90deg, rgba(2,0,36,1) 0%, rgba(238,65,79,1) 42%, rgba(0,84,255,1) 81%); \n",
       "    padding: 0.25em;\n",
       "}\n",
       "\n",
       "h3 {\n",
       "    color: white;\n",
       "    background-color: black;\n",
       "    padding: 0.25em;\n",
       "}\n",
       "\n",
       "h2 {\n",
       "    color: white;\n",
       "    background-color: #fc0362;\n",
       "    padding: 0.25em;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "css = open('notebook_css/style-table.css').read() + open('notebook_css/style-notebook.css').read()\n",
    "HTML('<style>{}</style>'.format(css))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-certification",
   "metadata": {},
   "source": [
    "# Optimizing Model Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-uncle",
   "metadata": {},
   "source": [
    "## Jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "interesting-contact",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "terminal-africa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1.]], requires_grad=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = torch.eye(5, requires_grad=True)\n",
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "existing-browser",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1., 1., 1., 1.],\n",
       "        [1., 4., 1., 1., 1.],\n",
       "        [1., 1., 4., 1., 1.],\n",
       "        [1., 1., 1., 4., 1.],\n",
       "        [1., 1., 1., 1., 4.]], grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = (inp + 1).pow(2)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "comic-bulgarian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Call:\n",
      "tensor([[4., 2., 2., 2., 2.],\n",
      "        [2., 4., 2., 2., 2.],\n",
      "        [2., 2., 4., 2., 2.],\n",
      "        [2., 2., 2., 4., 2.],\n",
      "        [2., 2., 2., 2., 4.]])\n"
     ]
    }
   ],
   "source": [
    "out.backward(gradient=torch.ones_like(inp), retain_graph=True)\n",
    "print(f\"First Call:\\n{inp.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "thousand-ready",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second Call:\n",
      "tensor([[8., 4., 4., 4., 4.],\n",
      "        [4., 8., 4., 4., 4.],\n",
      "        [4., 4., 8., 4., 4.],\n",
      "        [4., 4., 4., 8., 4.],\n",
      "        [4., 4., 4., 4., 8.]])\n"
     ]
    }
   ],
   "source": [
    "out.backward(gradient=torch.ones_like(inp), retain_graph=True)\n",
    "print(f\"Second Call:\\n{inp.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "wired-paragraph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Third Call:\n",
      "tensor([[4., 2., 2., 2., 2.],\n",
      "        [2., 4., 2., 2., 2.],\n",
      "        [2., 2., 4., 2., 2.],\n",
      "        [2., 2., 2., 4., 2.],\n",
      "        [2., 2., 2., 2., 4.]])\n"
     ]
    }
   ],
   "source": [
    "inp.grad.zero_()\n",
    "out.backward(gradient=torch.ones_like(inp), retain_graph=True)\n",
    "print(f\"Third Call:\\n{inp.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "stable-interpretation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fourth Call:\n",
      "tensor([[4., 2., 2., 2., 2.],\n",
      "        [2., 4., 2., 2., 2.],\n",
      "        [2., 2., 4., 2., 2.],\n",
      "        [2., 2., 2., 4., 2.],\n",
      "        [2., 2., 2., 2., 4.]])\n"
     ]
    }
   ],
   "source": [
    "inp.grad.zero_()\n",
    "out.backward(gradient=torch.ones_like(inp), retain_graph=True)\n",
    "print(f\"Fourth Call:\\n{inp.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-variable",
   "metadata": {},
   "source": [
    "Previously we were calling `backward()` (without function parameters).\n",
    "\n",
    "This is essentially equivalent to calling `backward(torch.tensor(1.0))` which is a useful way to compute gradients in case of a scalar valued function; such as **loss** during NN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-architect",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "clinical-cincinnati",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-giant",
   "metadata": {},
   "source": [
    "We initialize the optimizer by registering model parameters that need to be optimized and passing in the learning rate `lr`\n",
    "\n",
    "Inside the training loop; optimization happend in three steps:\n",
    "\n",
    "1. Call `optimizer.zero_grad()` to reset the gradients of the model parameters. Gradients by default adds up; to prevent counting we explicitly zero tem at each iteration\n",
    "\n",
    "2. Backpropagate the prediction loss with `loss.backwards()`. PyTorch deposits the gradients w.r.t each parameter.\n",
    "\n",
    "3. Once we have the graients we call `optimizer.step()` to adjust the weights of the parameters based on the graients collected in the backward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-demonstration",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(params=model.parameter(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "south-edinburgh",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "biological-seminar",
   "metadata": {},
   "source": [
    "## Full Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "educated-municipality",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        ## compute prediction & loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        ## Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss = loss.item()\n",
    "            current = bacth * len(X)\n",
    "            print(f\"loss: {loss:>7f} | [{current:5d} / {size:5d}]\")\n",
    "            \n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss = 0.\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "            test_loss += loss.item()\n",
    "            correct += (pred.argmax(dim=-1) == y).type(torch.float).sum().item()\n",
    "        \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error:\\nAvg. loss: {test_loss:>8f} | Accuracy: {(100*correct):>0.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "superb-sigma",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-5c4e005d1836>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch [{t+1}]:{'--'*15}\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch [{t+1}]:{'--'*15}\\n\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn, optimizer)\n",
    "print(f\"DONE!!🎯🎯\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-criterion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "running-narrow",
   "metadata": {},
   "source": [
    "# Saving & Loading a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "naughty-bookmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "expressed-heath",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /Users/imflash217/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87c6e2b2a76647babb0d5d9d220446f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet18 = models.resnet18(pretrained=True)\n",
    "resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "attended-defeat",
   "metadata": {},
   "outputs": [],
   "source": [
    "for params in resnet18.parameters():\n",
    "    params.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "super-heath",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "revised-position",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=10, bias=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet18.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "arranged-motel",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18.fc = nn.Linear(in_features=512, out_features=10, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "split-extraction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=10, bias=True)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet18.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "hazardous-consistency",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "novel-faith",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "torch.Size([10])\n",
      "Parameter containing:\n",
      "tensor([ 0.0262,  0.0441, -0.0406, -0.0184,  0.0055, -0.0107, -0.0008, -0.0121,\n",
      "        -0.0333,  0.0437], requires_grad=True)\n",
      "True\n",
      "\n",
      "------------------------------\n",
      "torch.Size([10, 512])\n",
      "Parameter containing:\n",
      "tensor([[-0.0134,  0.0272,  0.0418,  ...,  0.0233,  0.0384,  0.0063],\n",
      "        [-0.0073, -0.0319,  0.0230,  ..., -0.0347, -0.0302,  0.0288],\n",
      "        [ 0.0349,  0.0128,  0.0341,  ..., -0.0132, -0.0108,  0.0062],\n",
      "        ...,\n",
      "        [ 0.0113,  0.0283,  0.0197,  ...,  0.0263,  0.0314,  0.0398],\n",
      "        [-0.0339, -0.0300,  0.0410,  ..., -0.0178,  0.0176,  0.0381],\n",
      "        [-0.0310,  0.0348, -0.0219,  ...,  0.0062, -0.0208,  0.0253]],\n",
      "       requires_grad=True)\n",
      "True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, param in enumerate(reversed(list(resnet18.parameters()))):\n",
    "    if i > 1: break\n",
    "    print(f\"{'---'*10}\")\n",
    "    print(f\"{param.shape}\\n{param}\\n{param.requires_grad}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "textile-comparative",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4, 5])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(size=(2,3,4,5))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "static-worth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.flatten(x, 0)\n",
    "y.shape                      ## [2*3*4*5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "affecting-dodge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 60])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.flatten(x, 1)\n",
    "y.shape                      ## [2, 3*4*5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "excess-mainstream",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 20])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.flatten(x, 2)\n",
    "y.shape                      ## [2, 3, 4*5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "presidential-circle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "A kind of Tensor that is to be considered a module parameter.\n",
       "\n",
       "Parameters are :class:`~torch.Tensor` subclasses, that have a\n",
       "very special property when used with :class:`Module` s - when they're\n",
       "assigned as Module attributes they are automatically added to the list of\n",
       "its parameters, and will appear e.g. in :meth:`~Module.parameters` iterator.\n",
       "Assigning a Tensor doesn't have such effect. This is because one might\n",
       "want to cache some temporary state, like last hidden state of the RNN, in\n",
       "the model. If there was no such class as :class:`Parameter`, these\n",
       "temporaries would get registered too.\n",
       "\n",
       "Arguments:\n",
       "    data (Tensor): parameter tensor.\n",
       "    requires_grad (bool, optional): if the parameter requires gradient. See\n",
       "        :ref:`excluding-subgraphs` for more details. Default: `True`\n",
       "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/lib/python3.7/site-packages/torch/nn/parameter.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn.Parameter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dental-factory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.parameter.Parameter"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "adjusted-partnership",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.2371, 0.3433, 0.3279, 0.4642, 0.2233, 0.2370, 0.2176, 0.3793, 0.3140,\n",
       "        0.2803, 0.2434, 0.2116, 0.2478, 0.2435, 0.2298, 0.3172, 0.2725, 0.6511,\n",
       "        0.2925, 0.2281, 0.2279, 0.4254, 0.2342, 0.3328, 0.2632, 0.2176, 0.3180,\n",
       "        0.3893, 0.1387, 0.2274, 0.3379, 0.0767, 0.2253, 0.2504, 0.1990, 0.1951,\n",
       "        0.2566, 0.3253, 0.2797, 0.3149, 0.2373, 0.2533, 0.1956, 0.3236, 0.2093,\n",
       "        0.2333, 0.2300, 0.5019, 0.2830, 0.1885, 0.3264, 0.2722, 0.2369, 0.2430,\n",
       "        0.3625, 0.2165, 0.4700, 0.3047, 0.3675, 0.2641, 0.1979, 0.2664, 0.3448,\n",
       "        0.2005, 0.2450, 0.4351, 0.2689, 0.1632, 0.3087, 0.1209, 0.2153, 0.1592,\n",
       "        0.2960, 0.1423, 0.2951, 0.2706, 0.2007, 0.2939, 0.2210, 0.2243, 0.2465,\n",
       "        0.3910, 0.4599, 0.5417, 0.2147, 0.3469, 0.2703, 0.2229, 0.3645, 0.2647,\n",
       "        0.2421, 0.2492, 0.1666, 0.2763, 0.2560, 0.2151, 0.3363, 0.2767, 0.2516,\n",
       "        0.2988, 0.2622, 0.3499, 0.3001, 0.3907, 0.3184, 0.2233, 0.2649, 0.2110,\n",
       "        0.2034, 0.2752, 0.2314, 0.3480, 0.2238, 0.2892, 0.1991, 0.2923, 0.3259,\n",
       "        0.0722, 0.3039, 0.3041, 0.3803, 0.2568, 0.2382, 0.3057, 0.2652, 0.1532,\n",
       "        0.2110, 0.2567, 0.3148, 0.2746, 0.1833, 0.1950, 0.1116, 0.2279, 0.3705,\n",
       "        0.2477, 0.2000, 0.3060, 0.2548, 0.2468, 0.3028, 0.1921, 0.2952, 0.1980,\n",
       "        0.2135, 0.1583, 0.1586, 0.3944, 0.2352, 0.3947, 0.2740, 0.2861, 0.1856,\n",
       "        0.2702, 0.2986, 0.1728, 0.2658, 0.2696, 0.2028, 0.1838, 0.3176, 0.6246,\n",
       "        0.2631, 0.3855, 0.2074, 0.2317, 0.4171, 0.2044, 0.2926, 0.3506, 0.2305,\n",
       "        0.2400, 0.1420, 0.1093, 0.2757, 0.3253, 0.2334, 0.1650, 0.4026, 0.2066,\n",
       "        0.1790, 0.3032, 0.5658, 0.3246, 0.3834, 0.3254, 0.1772, 0.2909, 0.2350,\n",
       "        0.2519, 0.1968, 0.2003, 0.3213, 0.4802, 0.2543, 0.2578, 0.3280, 0.2270,\n",
       "        0.3044, 0.2273, 0.2447, 0.2527, 0.4136, 0.2588, 0.3589, 0.2688, 0.2115,\n",
       "        0.2022, 0.3186, 0.3740, 0.1785, 0.2074, 0.2346, 0.3566, 0.2623, 0.2620,\n",
       "        0.2880, 0.1462, 0.1896, 0.2777, 0.1852, 0.3240, 0.2748, 0.2164, 0.3066,\n",
       "        0.1845, 0.3992, 0.1695, 0.4411, 0.2812, 0.2730, 0.2784, 0.1861, 0.3589,\n",
       "        0.1934, 0.3320, 0.3350, 0.2655, 0.2740, 0.3185, 0.2633, 0.2458, 0.2003,\n",
       "        0.2809, 0.3049, 0.2050, 0.2904, 0.2381, 0.3278, 0.3484, 0.4293, 0.2422,\n",
       "        0.2859, 0.1864, 0.2954, 0.5634, 0.2081, 0.3743, 0.2902, 0.3820, 0.3069,\n",
       "        0.2101, 0.2750, 0.2878, 0.1870, 0.3015, 0.1661, 0.2998, 0.3101, 0.2522,\n",
       "        0.2419, 0.1758, 0.2681, 0.2812, 0.1495, 0.2868, 0.3157, 0.2587, 0.2437,\n",
       "        0.1467, 0.5416, 0.2490, 0.2831, 0.2783, 0.1614, 0.1963, 0.2034, 0.2364,\n",
       "        0.2527, 0.1573, 0.3184, 0.2841, 0.1613, 0.1489, 0.2850, 0.1625, 0.3277,\n",
       "        0.4936, 0.2780, 0.3178, 0.1743, 0.2158, 0.2222, 0.2821, 0.4267, 0.2713,\n",
       "        0.1778, 0.3067, 0.2270, 0.1772, 0.3897, 0.2923, 0.4843, 0.2345, 0.2327,\n",
       "        0.2740, 0.2700, 0.2804, 0.4035, 0.1501, 0.3329, 0.3286, 0.2803, 0.2309,\n",
       "        0.1738, 0.3270, 0.3097, 0.1808, 0.2384, 0.2107, 0.3240, 0.3346, 0.2236,\n",
       "        0.2061, 0.2687, 0.2360, 0.3338, 0.2694, 0.3203, 0.2895, 0.1884, 0.1491,\n",
       "        0.3957, 0.5167, 0.3407, 0.1854, 0.1816, 0.2626, 0.1855, 0.2219, 0.1482,\n",
       "        0.2584, 0.2458, 0.2616, 0.2396, 0.2402, 0.2423, 0.3463, 0.2731, 0.1524,\n",
       "        0.2514, 0.2760, 0.1734, 0.2715, 0.4052, 0.2252, 0.3676, 0.3070, 0.3127,\n",
       "        0.1836, 0.4330, 0.2203, 0.2073, 0.2803, 0.2984, 0.2191, 0.3272, 0.2267,\n",
       "        0.2749, 0.3056, 0.4566, 0.2962, 0.3528, 0.3236, 0.4220, 0.2715, 0.2256,\n",
       "        0.2903, 0.1829, 0.3994, 0.2820, 0.2471, 0.1647, 0.3654, 0.4504, 0.2685,\n",
       "        0.2992, 0.2825, 0.2435, 0.2212, 0.4300, 0.4342, 0.1988, 0.2863, 0.3398,\n",
       "        0.2444, 0.2905, 0.2559, 0.2586, 0.1702, 0.1906, 0.2536, 0.2978, 0.2498,\n",
       "        0.3777, 0.2252, 0.2472, 0.2243, 0.1732, 0.2194, 0.2091, 0.2820, 0.2898,\n",
       "        0.2887, 0.3292, 0.1644, 0.2962, 0.3279, 0.2535, 0.2795, 0.2238, 0.2607,\n",
       "        0.1937, 0.2680, 0.2418, 0.5193, 0.2502, 0.3147, 0.2166, 0.2313, 0.2027,\n",
       "        0.1880, 0.2180, 0.3826, 0.3871, 0.2358, 0.3556, 0.2272, 0.3272, 0.3442,\n",
       "        0.3154, 0.1993, 0.3135, 0.2254, 0.3048, 0.2658, 0.3337, 0.2679, 0.2670,\n",
       "        0.2363, 0.4347, 0.1931, 0.1995, 0.2072, 0.3202, 0.2667, 0.2305, 0.2383,\n",
       "        0.2246, 0.2562, 0.2837, 0.4046, 0.2786, 0.2243, 0.1591, 0.1923, 0.1894,\n",
       "        0.2496, 0.1140, 0.3128, 0.3197, 0.3530, 0.2999, 0.2115, 0.4718, 0.2979,\n",
       "        0.3472, 0.2890, 0.4740, 0.2230, 0.3630, 0.4015, 0.2446, 0.1897, 0.1460,\n",
       "        0.1874, 0.2734, 0.2366, 0.3001, 0.2359, 0.2688, 0.3256, 0.2749, 0.2848,\n",
       "        0.2299, 0.3001, 0.4818, 0.3074, 0.3164, 0.3114, 0.3549, 0.2859])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "average-junction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Records operation history and defines formulas for differentiating ops.\n",
       "\n",
       "See the Note on extending the autograd engine for more details on how to use\n",
       "this class: https://pytorch.org/docs/stable/notes/extending.html#extending-torch-autograd\n",
       "\n",
       "Every operation performed on :class:`Tensor` s creates a new function\n",
       "object, that performs the computation, and records that it happened.\n",
       "The history is retained in the form of a DAG of functions, with edges\n",
       "denoting data dependencies (``input <- output``). Then, when backward is\n",
       "called, the graph is processed in the topological ordering, by calling\n",
       ":func:`backward` methods of each :class:`Function` object, and passing\n",
       "returned gradients on to next :class:`Function` s.\n",
       "\n",
       "Normally, the only way users interact with functions is by creating\n",
       "subclasses and defining new operations. This is a recommended way of\n",
       "extending torch.autograd.\n",
       "\n",
       "Examples::\n",
       "\n",
       "    >>> class Exp(Function):\n",
       "    >>>\n",
       "    >>>     @staticmethod\n",
       "    >>>     def forward(ctx, i):\n",
       "    >>>         result = i.exp()\n",
       "    >>>         ctx.save_for_backward(result)\n",
       "    >>>         return result\n",
       "    >>>\n",
       "    >>>     @staticmethod\n",
       "    >>>     def backward(ctx, grad_output):\n",
       "    >>>         result, = ctx.saved_tensors\n",
       "    >>>         return grad_output * result\n",
       "    >>>\n",
       "    >>> #Use it by calling the apply method:\n",
       "    >>> output = Exp.apply(input)\n",
       "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/lib/python3.7/site-packages/torch/autograd/function.py\n",
       "\u001b[0;31mType:\u001b[0m           FunctionMeta\n",
       "\u001b[0;31mSubclasses:\u001b[0m     InplaceFunction, NestedIOFunction, SyncBatchNorm, CrossMapLRN2d, Broadcast, ReduceAddCoalesced, Gather, Scatter, _Dirichlet, LOBPCGAutogradFunction, ...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.autograd.Function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "uniform-omaha",
   "metadata": {},
   "outputs": [],
   "source": [
    "param.data.sub_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-textbook",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "becoming-calcium",
   "metadata": {},
   "source": [
    "# Training a Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "lesbian-designation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "norwegian-valentine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c0b35b835f548d18e5a64de990e8de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/cifar-10-python.tar.gz to data/\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root=\"data/\",\n",
    "                                             train=True,\n",
    "                                             download=True, \n",
    "                                             transform=transform,\n",
    "                                            )\n",
    "test_dataset = torchvision.datasets.CIFAR10(root=\"data/\", \n",
    "                                            train=False, \n",
    "                                            download=True, \n",
    "                                            transform=transform,\n",
    "                                           )\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                               batch_size=batch_size, \n",
    "                                               shuffle=True,\n",
    "                                               num_workers=2,\n",
    "                                              )\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=False,\n",
    "                                              num_workers=2,\n",
    "                                             )\n",
    "\n",
    "classes = (\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \n",
    "           \"dog\", \"frog\", \"horse\", \"ship\", \"truck\",)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "classified-dryer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10000)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "czech-explanation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 36, 138]) (3, 36, 138) (36, 138, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horse cat car ship\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def show_image(img):\n",
    "    \"\"\"Plots the image\"\"\"\n",
    "    img = img/2 + 0.5\n",
    "    img_np = img.numpy()\n",
    "    img_t = np.transpose(img_np, axes=(-2, -1, -3))\n",
    "    print(img.shape, img_np.shape, img_t.shape)\n",
    "    plt.imshow(img_t)\n",
    "    plt.show()\n",
    "    \n",
    "## get some random image\n",
    "images, labels = next(iter(train_dataloader))\n",
    "\n",
    "## show images\n",
    "show_image(torchvision.utils.make_grid(images))\n",
    "\n",
    "## print labels\n",
    "print(\" \".join(classes[i] for i in labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-league",
   "metadata": {},
   "source": [
    "## Define a Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "christian-prefix",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=(5,5))\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2,2))\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=(5,5))\n",
    "        self.fc1 = nn.Linear(in_features=16*5*5, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
    "        self.fc3 = nn.Linear(in_features=84, out_features=10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "governing-affair",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "combined-mobility",
   "metadata": {},
   "source": [
    "## Define a loss function & an optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "periodic-walnut",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(params=net.parameters(), lr=1e-3, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "restricted-allen",
   "metadata": {},
   "source": [
    "## Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "centered-canyon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💈Epoch[ 1/20]\n",
      "\t minibatch[ 2000] | running_loss: 2.28487\n",
      "\t minibatch[ 4000] | running_loss: 1.96404\n",
      "\t minibatch[ 6000] | running_loss: 1.75157\n",
      "\t minibatch[ 8000] | running_loss: 1.63266\n",
      "\t minibatch[10000] | running_loss: 1.55427\n",
      "\t minibatch[12000] | running_loss: 1.49077\n",
      "💈Epoch[ 2/20]\n",
      "\t minibatch[ 2000] | running_loss: 1.40760\n",
      "\t minibatch[ 4000] | running_loss: 1.37755\n",
      "\t minibatch[ 6000] | running_loss: 1.36043\n",
      "\t minibatch[ 8000] | running_loss: 1.33459\n",
      "\t minibatch[10000] | running_loss: 1.30502\n",
      "\t minibatch[12000] | running_loss: 1.28475\n",
      "💈Epoch[ 3/20]\n",
      "\t minibatch[ 2000] | running_loss: 1.21293\n",
      "\t minibatch[ 4000] | running_loss: 1.22123\n",
      "\t minibatch[ 6000] | running_loss: 1.18209\n",
      "\t minibatch[ 8000] | running_loss: 1.20947\n",
      "\t minibatch[10000] | running_loss: 1.17915\n",
      "\t minibatch[12000] | running_loss: 1.18546\n",
      "💈Epoch[ 4/20]\n",
      "\t minibatch[ 2000] | running_loss: 1.08842\n",
      "\t minibatch[ 4000] | running_loss: 1.11599\n",
      "\t minibatch[ 6000] | running_loss: 1.10871\n",
      "\t minibatch[ 8000] | running_loss: 1.10635\n",
      "\t minibatch[10000] | running_loss: 1.10320\n",
      "\t minibatch[12000] | running_loss: 1.09834\n",
      "💈Epoch[ 5/20]\n",
      "\t minibatch[ 2000] | running_loss: 1.01052\n",
      "\t minibatch[ 4000] | running_loss: 1.02543\n",
      "\t minibatch[ 6000] | running_loss: 1.00112\n",
      "\t minibatch[ 8000] | running_loss: 1.05956\n",
      "\t minibatch[10000] | running_loss: 1.03824\n",
      "\t minibatch[12000] | running_loss: 1.04068\n",
      "💈Epoch[ 6/20]\n",
      "\t minibatch[ 2000] | running_loss: 0.94984\n",
      "\t minibatch[ 4000] | running_loss: 0.95801\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-e4709b6f4339>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m## backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0\n",
    "    print(f\"💈Epoch[{epoch+1:2d}/{num_epochs:2d}]\")\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        ## calculate the loss\n",
    "        pred = net(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        ## backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        ## log the statistics\n",
    "        running_loss += loss.item()\n",
    "        if batch % 2000 == 1999:\n",
    "            print(f\"\\t minibatch[{(batch+1):>5d}] | running_loss: {(running_loss/2000):.5f}\")\n",
    "            running_loss = 0.0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "following-thousand",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "combined-teddy",
   "metadata": {},
   "source": [
    "# Inside of PyTorch (by @jphoward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "alone-locator",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "first-packet",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"data\")\n",
    "PATH = DATA_PATH / \"mnist\"\n",
    "\n",
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "URL = \"https://github.com/pytorch/tutorials/raw/master/_static/\"\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "if not (PATH / FILENAME).exists():\n",
    "    content = requests.get(URL + FILENAME).content\n",
    "    (PATH / FILENAME).open(\"wb\").write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "rapid-clerk",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('data/mnist')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "advance-checkout",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
    "    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "vital-amazon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 784), (50000,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "traditional-refrigerator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 784), (10000,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bottom-apparel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.imshow(x_train[0].reshape(28, 28))\n",
    "plt.show()\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "statutory-airport",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([50000, 784])\n",
      "tensor(0) tensor(9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/imflash217/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x_train, y_train, x_valid, y_valid = map(torch.tensor, \n",
    "                                          (x_train, y_train, x_valid, y_valid)\n",
    "                                         )\n",
    "\n",
    "n, c = x_train.shape\n",
    "print(x_train)\n",
    "print(x_train.shape)\n",
    "print(y_train.min(), y_train.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "discrete-weapon",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 🎯🎯🎯🎯\n",
    "##\n",
    "import math\n",
    "\n",
    "weights = torch.randn(size=(784,10)) / math.sqrt(784)\n",
    "weights.requires_grad_(True)\n",
    "bias = torch.zeros(size=(10,), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bronze-scheme",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "entitled-adapter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "manufactured-tractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 🎯🎯🎯🎯\n",
    "##\n",
    "\n",
    "def log_softmax(x):\n",
    "    residue = x.exp().sum(-1).log().unsqueeze(-1)\n",
    "    return x - residue\n",
    "\n",
    "def model(x_batch):\n",
    "    out_batch = x_batch @ weights + bias\n",
    "    return log_softmax(out_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "coral-writing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.1465, -1.8755, -2.4180, -2.1391, -1.9722, -2.6350, -2.7429, -2.2622,\n",
      "        -2.5418, -2.7354], grad_fn=<SelectBackward>) \n",
      "\n",
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "## 🎯🎯🎯🎯\n",
    "##\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "x_batch = x_train[:batch_size]\n",
    "pred_batch = model(x_batch)\n",
    "\n",
    "print(pred_batch[0], \"\\n\")\n",
    "print(pred_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "frank-innocent",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 🎯🎯🎯🎯\n",
    "##\n",
    "\n",
    "def nll(input_, target_):\n",
    "    return -input_[range(target_.shape[0]), target_].mean()\n",
    "\n",
    "loss_fn = nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "executed-width",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3431, grad_fn=<NegBackward>)\n"
     ]
    }
   ],
   "source": [
    "## 🎯🎯🎯🎯\n",
    "##\n",
    "y_batch = y_train[:batch_size]\n",
    "loss = loss_fn(pred_batch, y_batch)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "earned-intervention",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 🎯🎯🎯🎯\n",
    "##\n",
    "\n",
    "def accuracy(output_, y_batch):\n",
    "    preds = torch.argmax(output_, dim=-1)\n",
    "    return (preds == y_batch).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "union-explorer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0625)\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy(pred_batch, y_batch)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "selected-century",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1/2]\n",
      "\t batch [ 199 / 782]|  loss: 0.26843\n",
      "\t batch [ 399 / 782]|  loss: 0.34530\n",
      "\t batch [ 599 / 782]|  loss: 0.28558\n",
      "\n",
      "Epoch [2/2]\n",
      "\t batch [ 199 / 782]|  loss: 0.26778\n",
      "\t batch [ 399 / 782]|  loss: 0.34566\n",
      "\t batch [ 599 / 782]|  loss: 0.28462\n"
     ]
    }
   ],
   "source": [
    "## 🎯🎯🎯🎯\n",
    "##\n",
    "\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "lr = 0.5\n",
    "num_epochs = 2\n",
    "num_batches = (n-1) // batch_size + 1\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch [{epoch+1}/{num_epochs}]\")\n",
    "    for i in range(num_batches):\n",
    "        ## set_trace()\n",
    "        start_i = i * batch_size\n",
    "        end_i = start_i + batch_size\n",
    "        x_batch = x_train[start_i:end_i]      ## grab a minibatch of data\n",
    "        y_batch = y_train[start_i:end_i]\n",
    "        \n",
    "        pred_batch = model(x_batch)\n",
    "        loss = loss_fn(pred_batch, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            weights -= weights.grad * lr\n",
    "            bias -= bias.grad * lr\n",
    "            weights.grad.zero_()\n",
    "            bias.grad.zero_()\n",
    "        if i % 200 == 199:\n",
    "            print(f\"\\t batch [{i:4d} /{num_batches:4d}]|  loss: {loss.item():.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "isolated-buyer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0502, grad_fn=<NegBackward>), tensor(1.))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(model(x_batch), y_batch), accuracy(model(x_batch), y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "working-snapshot",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "generous-theory",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 🎯🎯🎯🎯\n",
    "##\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "loss_fn = F.cross_entropy\n",
    "\n",
    "def model(x_batch):\n",
    "    return x_batch @ weights + bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "private-lighter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0502, grad_fn=<NllLossBackward>), tensor(1.))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(model(x_batch), y_batch), accuracy(model(x_batch), y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-scholar",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bound-tuesday",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 🎯🎯🎯🎯\n",
    "##\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "class MNIST_Logistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(size=(784, 10)) / math.sqrt(784))\n",
    "        self.bias = nn.Parameter(torch.zeros(size=(10,)))\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return xb @ self.weights + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "particular-combat",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNIST_Logistic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "boolean-protein",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MNIST_Logistic()"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "random-constitution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4465, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(loss_fn(model(x_batch), y_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "greek-possession",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'NoneType' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-ff385943dcc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'NoneType' and 'float'"
     ]
    }
   ],
   "source": [
    "## 🎯🎯🎯🎯\n",
    "##\n",
    "\n",
    "with torch.no_grad():\n",
    "    for p in model.parameters():\n",
    "        p -= p.grad * lr\n",
    "    model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "distributed-turtle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "qualified-battlefield",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 🎯🎯🎯🎯\n",
    "##\n",
    "\n",
    "def fit():\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\n Epoch [{epoch+1}/{num_epochs}]\")\n",
    "        for i in range(num_batches):\n",
    "            start_i = i * batch_size\n",
    "            end_i = start_i + batch_size\n",
    "            xb = x_train[start_i:end_i]\n",
    "            yb = y_train[start_i:end_i]\n",
    "            pred = model(xb)\n",
    "            loss = loss_fn(pred, yb)\n",
    "            \n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():\n",
    "                    p -= p.grad * lr\n",
    "                model.zero_grad()\n",
    "            if i % 200 == 0:\n",
    "                print(f\"\\t minibatch [{i:4d} / {num_batches:4d}] | loss: {loss.item()}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "blind-gardening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch [1/2]\n",
      "\t minibatch [   0 /  782] | loss: 0.19421565532684326\n",
      "\t minibatch [ 200 /  782] | loss: 0.17413318157196045\n",
      "\t minibatch [ 400 /  782] | loss: 0.19378973543643951\n",
      "\t minibatch [ 600 /  782] | loss: 0.20261113345623016\n",
      "\n",
      " Epoch [2/2]\n",
      "\t minibatch [   0 /  782] | loss: 0.18589738011360168\n",
      "\t minibatch [ 200 /  782] | loss: 0.17140400409698486\n",
      "\t minibatch [ 400 /  782] | loss: 0.19101333618164062\n",
      "\t minibatch [ 600 /  782] | loss: 0.1987023800611496\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "virgin-section",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0604, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(loss_fn(model(x_batch), y_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-european",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "physical-resistance",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 🎯🎯🎯🎯\n",
    "##\n",
    "\n",
    "class MNIST_Logistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Linear(in_features=784, out_features=10)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return self.lin(xb)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "adapted-lexington",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2893, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = MNIST_Logistic()\n",
    "print(loss_fn(model(x_batch), y_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "going-faculty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch [1/2]\n",
      "\t minibatch [   0 /  782] | loss: 2.303011894226074\n",
      "\t minibatch [ 200 /  782] | loss: 0.30543839931488037\n",
      "\t minibatch [ 400 /  782] | loss: 0.23813964426517487\n",
      "\t minibatch [ 600 /  782] | loss: 0.26431015133857727\n",
      "\n",
      " Epoch [2/2]\n",
      "\t minibatch [   0 /  782] | loss: 0.28001660108566284\n",
      "\t minibatch [ 200 /  782] | loss: 0.1976470947265625\n",
      "\t minibatch [ 400 /  782] | loss: 0.21188215911388397\n",
      "\t minibatch [ 600 /  782] | loss: 0.22766846418380737\n",
      "tensor(0.0804, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = MNIST_Logistic()\n",
    "fit()\n",
    "print(loss_fn(model(x_batch), y_batch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shared-banking",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "underlying-texas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2972, grad_fn=<NllLossBackward>)\n",
      "--------------------------------------------------\n",
      "Epoch[1/2]\n",
      "\t minibatch[   0 /  782] | loss: 2.35864\n",
      "\t minibatch[ 200 /  782] | loss: 0.29606\n",
      "\t minibatch[ 400 /  782] | loss: 0.23349\n",
      "\t minibatch[ 600 /  782] | loss: 0.26183\n",
      "--------------------------------------------------\n",
      "Epoch[2/2]\n",
      "\t minibatch[   0 /  782] | loss: 0.27752\n",
      "\t minibatch[ 200 /  782] | loss: 0.19458\n",
      "\t minibatch[ 400 /  782] | loss: 0.20846\n",
      "\t minibatch[ 600 /  782] | loss: 0.22680\n",
      "--------------------------------------------------\n",
      "tensor(0.0831, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "## 🎯🎯🎯🎯\n",
    "##\n",
    "\n",
    "from torch import optim\n",
    "\n",
    "def get_model():\n",
    "    model = MNIST_Logistic()\n",
    "    return model, optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "model, opt = get_model()\n",
    "print(loss_fn(model(x_batch), y_batch))\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"{'--'*25}\\nEpoch[{epoch+1}/{num_epochs}]\")\n",
    "    for i in range(num_batches):\n",
    "        start_i = i * batch_size\n",
    "        end_i = start_i + batch_size\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        \n",
    "        pred = model(xb)\n",
    "        loss = loss_fn(pred, yb)\n",
    "        \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        if i%200 == 0:\n",
    "            print(f\"\\t minibatch[{i:4d} / {num_batches:4d}] | loss: {loss.item():.5f}\")\n",
    "print(f\"{'--'*25}\")\n",
    "print(loss_fn(model(x_batch), y_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "light-hybrid",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "increasing-assault",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "personal-suite",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "municipal-slave",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 784])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "substantial-riding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = TensorDataset(x_train, y_train)\n",
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "pregnant-kinase",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 784]), torch.Size([5]))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = train_ds[0:5]\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "young-resistance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4, 1, 9])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "following-humidity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "historical-delight",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loss_batch(model, loss_fn, xb, yb, opt=None):\n",
    "    pred = model(xb)\n",
    "    loss = loss_fn(pred, yb)\n",
    "    if opt:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    return loss.item(), len(xb)\n",
    "    \n",
    "def fit(num_epochs, model, opt, loss_fn, train_dl, valid_dl):\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        model.train()\n",
    "        losses, nums = zip(*[loss_batch(model, loss_fn, xb, yb, opt) for xb, yb in train_dl])\n",
    "        train_loss = np.multiply(losses, nums).sum() / sum(nums)\n",
    "            \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_losses, val_nums = zip(*[loss_batch(model, loss_fn, xb, yb) for xb, yb in valid_dl])\n",
    "        val_loss = np.multiply(val_losses, val_nums).sum() / sum(val_nums)\n",
    "        \n",
    "        print(f\"Epoch [{(epoch+1):2d}/{num_epochs:2d}] | train_loss: {train_loss:4f} | valid_loss: {val_loss:4f}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "external-lawyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.func(x)\n",
    "\n",
    "def preprocess(x):\n",
    "    return x.view(-1, 1, 28, 28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "engaging-catalyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "valid_ds = torch.utils.data.TensorDataset(x_valid, y_valid)\n",
    "train_dl = torch.utils.data.DataLoader(dataset=train_ds, batch_size=64)\n",
    "valid_dl = torch.utils.data.DataLoader(dataset=valid_ds, batch_size=64*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "cognitive-saturday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [ 1/20] | train_loss: 1.145351 | valid_loss: 1.363253\n",
      "Epoch [ 2/20] | train_loss: 0.370123 | valid_loss: 0.358585\n",
      "Epoch [ 3/20] | train_loss: 0.276475 | valid_loss: 0.339897\n",
      "Epoch [ 4/20] | train_loss: 0.235609 | valid_loss: 0.271940\n",
      "Epoch [ 5/20] | train_loss: 0.211959 | valid_loss: 0.240838\n",
      "Epoch [ 6/20] | train_loss: 0.195047 | valid_loss: 0.210017\n",
      "Epoch [ 7/20] | train_loss: 0.180932 | valid_loss: 0.186624\n",
      "Epoch [ 8/20] | train_loss: 0.169549 | valid_loss: 0.193381\n",
      "Epoch [ 9/20] | train_loss: 0.160406 | valid_loss: 0.217786\n",
      "Epoch [10/20] | train_loss: 0.152626 | valid_loss: 0.240295\n",
      "Epoch [11/20] | train_loss: 0.146434 | valid_loss: 0.237679\n",
      "Epoch [12/20] | train_loss: 0.140819 | valid_loss: 0.218612\n",
      "Epoch [13/20] | train_loss: 0.135939 | valid_loss: 0.219150\n",
      "Epoch [14/20] | train_loss: 0.131477 | valid_loss: 0.195003\n",
      "Epoch [15/20] | train_loss: 0.127360 | valid_loss: 0.186916\n",
      "Epoch [16/20] | train_loss: 0.123758 | valid_loss: 0.170595\n",
      "Epoch [17/20] | train_loss: 0.120180 | valid_loss: 0.159786\n",
      "Epoch [18/20] | train_loss: 0.117299 | valid_loss: 0.150409\n",
      "Epoch [19/20] | train_loss: 0.114590 | valid_loss: 0.143035\n",
      "Epoch [20/20] | train_loss: 0.111979 | valid_loss: 0.142072\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    Lambda(preprocess),\n",
    "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.AvgPool2d(kernel_size=4),\n",
    "    Lambda(lambda x: x.view(x.shape[0], -1)),\n",
    ")\n",
    "\n",
    "opt = optim.SGD(model.parameters(), lr=lr)\n",
    "fit(num_epochs=20, model=model, opt=opt, loss_fn=loss_fn, train_dl=train_dl, valid_dl=valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "million-smoke",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch.nn.functional.cross_entropy(input, target, weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean')>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "theoretical-publisher",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    lr: 0.5\n",
       "    momentum: 0\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "reserved-edward",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Lambda()\n",
       "  (1): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (2): ReLU()\n",
       "  (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (4): ReLU()\n",
       "  (5): Conv2d(16, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (6): ReLU()\n",
       "  (7): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
       "  (8): Lambda()\n",
       ")"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chronic-thesis",
   "metadata": {},
   "source": [
    "## Wrapped DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "premier-lover",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.func(x)\n",
    "\n",
    "    \n",
    "def preprocess(x, y):\n",
    "    return x.view(-1, 1, 28, 28), y\n",
    "\n",
    "\n",
    "class WrappedDataLoader:\n",
    "    def __init__(self, dl, func):\n",
    "        super().__init__()\n",
    "        self.dl = dl\n",
    "        self.func = func\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(dl)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for batch in self.dl:\n",
    "            yield self.func(*batch)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "promising-armenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dls(train_ds, valid_ds, bs):\n",
    "    train_dl = torch.utils.data.DataLoader(dataset=train_ds, batch_size=bs)\n",
    "    valid_dl = torch.utils.data.DataLoader(dataset=valid_ds, batch_size=2*bs)\n",
    "    return train_dl, valid_dl\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "unexpected-persian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "aboriginal-ghost",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "valid_ds = torch.utils.data.TensorDataset(x_valid, y_valid)\n",
    "train_dl, valid_dl = get_dls(train_ds, valid_ds, batch_size)\n",
    "train_dl = WrappedDataLoader(train_dl, preprocess)\n",
    "valid_dl = WrappedDataLoader(valid_dl, preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "underlying-switzerland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [ 1/20] | train_loss: 0.919512 | valid_loss: 0.569991\n",
      "Epoch [ 2/20] | train_loss: 0.471716 | valid_loss: 0.401526\n",
      "Epoch [ 3/20] | train_loss: 0.401352 | valid_loss: 0.309470\n",
      "Epoch [ 4/20] | train_loss: 0.411155 | valid_loss: 0.288481\n",
      "Epoch [ 5/20] | train_loss: 0.362021 | valid_loss: 0.296754\n",
      "Epoch [ 6/20] | train_loss: 0.407908 | valid_loss: 0.456740\n",
      "Epoch [ 7/20] | train_loss: 0.372598 | valid_loss: 0.307797\n",
      "Epoch [ 8/20] | train_loss: 0.354015 | valid_loss: 0.294139\n",
      "Epoch [ 9/20] | train_loss: 0.359534 | valid_loss: 0.325992\n",
      "Epoch [10/20] | train_loss: 0.335343 | valid_loss: 0.384450\n",
      "Epoch [11/20] | train_loss: 0.317497 | valid_loss: 0.273711\n",
      "Epoch [12/20] | train_loss: 0.344566 | valid_loss: 0.384467\n",
      "Epoch [13/20] | train_loss: 0.335513 | valid_loss: 0.354955\n",
      "Epoch [14/20] | train_loss: 0.333675 | valid_loss: 0.262305\n",
      "Epoch [15/20] | train_loss: 0.302853 | valid_loss: 0.278761\n",
      "Epoch [16/20] | train_loss: 0.313799 | valid_loss: 0.275258\n",
      "Epoch [17/20] | train_loss: 0.295675 | valid_loss: 0.285256\n",
      "Epoch [18/20] | train_loss: 0.317216 | valid_loss: 0.275086\n",
      "Epoch [19/20] | train_loss: 0.298794 | valid_loss: 0.325133\n",
      "Epoch [20/20] | train_loss: 0.314771 | valid_loss: 0.262371\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.AdaptiveAvgPool2d(1),\n",
    "    Lambda(lambda x: x.view(x.shape[0], -1)),\n",
    ")\n",
    "\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "fit(num_epochs=20, model=model, opt=opt, loss_fn=loss_fn, train_dl=train_dl, valid_dl=valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-design",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
